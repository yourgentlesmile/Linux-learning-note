# 终极失败

## hadoop写文件过程

1、客户端先使用DistributeFileSystem通过RPC请求，询问NameNode是否有权限写文件，并返回可以写入的DataNode列表  

2、获得应答后，将本地文件以block大小进行切片，向NameNode请求上传第一个block。  

3、DistributeFileSystem打开FsOutputStream通过TCP协议与第一个DataNode建立连接，同时，第一个Datanode，与第二个DataNode建立数据通道，第二个DataNode与第三个DataNode建立数据通道  

4、Client将数据以64K大小为一个packet的方式发送到DataNode，DataNode自己在落盘的时候也会将接受到的数据发往下一个DataNode，以此类推  

5、如果第二第三个DataNode失去联系，Client可以继续正常上传成功，如果是与Client交互的DataNode失去联系，则会上传失败。  

6、当全部上传完成后，Client会告诉NameNode上传完成。

## hdfs与client是如何通信的(用的是什么样的协议)，底层如何实现

同上

## hdfs小文件是如何处理的

可以使用 HAR，将小文件打包成一个大文件，也可以使用Sequence file  

HAR：  

优点：易操作，可以直接从hdfs查看  

缺点：  

1、访问内部文件需要先访问索引文件，效率比直接读取hdfs文件低  

2、创建的HAR跟源文件大小一致，且无法压缩  

3、创建后无法对HAR文件进行修改  

Sequence file是由二进制的kv组成，key是文件名，value是文件内容  

优点：支持压缩，占用空间更小  

缺点：不能追加写入，二进制不能直接阅读，需要使用指定类才能进行读写操作

## hdfs小文件过多会有什么影响

由于NameNode内存中保存了HDFS所有文件的元数据信息，一般每个文件元数据大小在150byte，如果小文件过多会导致NameNode内存占用过高，这里同时也制约了集群的扩展。同时读写大量小文件，需要频繁的在不同的DataNode之间切换，因此效率也不如读取几个大文件高。

## hdfs如何做HA，底层如何实现的

NameNode可以同时启动两个，使用ZKFC来进行主从切换，使用一组JournalNode来共享editlog  

**ZKFC**：会在每个NameNode所在的机器启动ZKFC，ZKFC会对所在的NN进行健康轮询，选举成功的ZKFC会在ZK上创建一个**/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb**节点，里面保存了Active NameNode的地址信息和一个/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock锁临时节点。  

当ZKFC发现自己监控的NN出现异常的时候会退出选举，关闭ZK连接，此时另外监听了这个临时节点的ZKFC就会创建这个临时节点，代表选举成功，此时会检查是否存在ActiveBreadCrumb这个节点，如果存在则会通过RPC的方式，将之前Active的节点转为standby，如果失败则启动fencing机制，使用SSH去把nn给KILL掉。(如果SSH也不成功则一直重试，是为了避免脑裂)，**处理方法就是在确定Active已经下线的情况下，重新hdfs zkfc -formatZK**就可以了  

Journal Node：EditLog的存储节点，以及做一些归并操作，Active NameNode会将edit log push到JournalNode。standby NameNode则每两分钟，从journal node pull edit log 到本地进行合并操作。也就是说，进行了主从切换，数据不一致的地方最多就是2分钟之间的数据。  

QJM使用epoch来防止脑裂，如果NameNode发送过来的消息中的epoch大于本地存储的epoch，则更新本地的epoch，如果小于，则拒绝写入。  

NameNode的epoch在每次主从切换时都会加一。  

## spark执行过程描述下，越细越好

1、当提交一个spark任务后，Driver向master申请资源。  

2、master根据需要的资源数，通知Worker启动相应的executorbackend，executorbackend会反向注册到driver中  

3、driver继续执行用户代码，遇到action算子，开始反向推算依赖，遇到宽依赖则划分stage，直到RDD没有父RDD，则依赖推算完成 。  

4、DagScheduler 划分完stage后，会提交stage中的taskset给taskScheduler，taskScheduler会将task分发给executor进行计算

## 灵魂三连追问-每个项目都问